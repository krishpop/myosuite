default:
    # - override hydra/output: local
    - override hydra/launcher: slurm_rich
  
hydra:
  launcher:
    timeout_min: 240
    account: juno
    partition: juno
    cpus_per_task: 8
    tasks_per_node: 
    gres: gpu:a5000:1
  job:
    name: ${job_name}


env               :   'myoHandPoseRandom-v0' #myosuite-v1          # placeholder name, not a real env
algorithm         :   PPO
seed              :   123
n_env             :   32
n_eval_env        :   5

# PPO object
policy            : 'MlpPolicy'
learning_rate     : 1e-5 
batch_size        : 256
gamma             : 0.95

# PPO.learn function
total_timesteps   : 15_000_000
log_interval      : 1000

eval_freq : 1000000
restore_checkpoint_freq : 500000
save_freq : 10000000

policy_kwargs:                                              # Policy parameters (initial STD and architecture)
  net_arch:
    - pi: [256, 128]
      vf: [256, 128]


# Algorithm hyperparameters : if alg requires additional params, can be specified here (or defaults will be used)
alg_hyper_params  :   {'device': 'cpu'}

job_name          :   ppo_sb3_${env}

hydra:
    job:
        name: ${env}
